\chapter*{Preface}
\addcontentsline{toc}{chapter}{Preface}

As the frontier of applied statistics pushes further and further, the
difficulty of problems has rapidly increased and has necessitated
sophisticated algorithmic solutions.  Many of the most successful
algorithms in modern data analysis leverage the geometry of the
problem, using derivatives of some objective function to simplify
the computations.

The ultimate utility of these algorithms, however, is limited by the
need for these derivatives to be made available to the algorithm,
an onerous task that obstructs many potential users.  Consequently,
automatic differentiation algorithms that can remove this burden
entirely are critical to the practical success of many advanced
statistical methods.

\nomad is an implementation of automatic differentiation particularly 
focused on performance and usability.  The library supports a wide-range 
of functions, including linear algebra routines via \textit{Eigen}, optimized
for first, second, and third-order derivatives.

Although certainly not exhaustive, this manual is meant to review
all aspects \nomad, including the theory behind automatic differentiation,
the details of the \nomad implementation, using \nomad in practice,
and then finally a reference guide documenting all of \nomad's features.

We thank Columbia University, University College London, and the University
of Warwick for their hospitality.  Michael Betancourt is supported under EPSRC 
grant EP/J016934/1.

\vspace{5mm}
\hfill The Nomad Development Team

\hfill \today