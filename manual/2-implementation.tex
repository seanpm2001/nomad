\chapter{Implementation}

\nomad is a \verb|C++| implementation of reverse mode automatic
differentiation that uses an \textit{operator overloading} strategy.
More precisely, we introduce a dual number type and then overload
common functions to accept this type.

A key difference of \nomad to other implementations is the generalization
to higher-orders.  Most higher-order automatic differentiation
implementations leverage the recursive nature of higher-order dual
numbers directly, automatically differentiating through a first-order
implementation to compute higher-order partial derivatives and
the subsequent operators.  This approach allows for
arbitrary-order automatic differentiation, but only at the cost of
inefficient and sometimes numerically unstable results.  \nomad,
on the other hand, explicitly implements second and third-order operators
with a focus on performance and numerical stability.

In this chapter we introduce the architecture behind the \nomad automatic 
differentiation implementation.  We view the internal representation of the 
expression graph and how it interfaces with function overloads before
discussing the user interface.

\section{Internal Representation of the Expression Graph}

While the expression graph represents the entire composite function, each
node in the expression graph represents just a single component function.  
Consequently each node must be responsible for both implementing the 
local pushforward and pullback of the corresponding function and storing 
the dual numbers, input nodes, and any auxiliary storage convenient for 
the operator implementations, like partial derivatives.
 
Like many other automatic differentiation implementations, \nomad
topologically sorts the expression graph into a linear stack of nodes, 
sometimes known as a tape (Figure \ref{fig:topologicalSort}).  This ordering 
preserves the structure of the expression graph, ensuring that a sweep 
through the stack executes a valid forward or reverse sweep through the 
expression graph.

\begin{figure}
\setlength{\unitlength}{0.1in} 
\centering
\begin{picture}(50, 20)
%
%\put(0, 0) { \framebox(50, 20){} }
%\put(25, 0) { \framebox(25, 30){} }
%\put(25, 0) { \framebox(6.25, 30){} }
%\put(25, 0) { \framebox(12.5, 30){} }
%\put(25, 0) { \framebox(18.75, 30){} }
%
%\put(25, 0) { \framebox(3.125, 30){} }
%\put(25, 0) { \framebox(9.375, 30){} }
%\put(25, 0) { \framebox(15.625, 30){} }
%
% Expression Graph
%
\put(6.25, 2.5) { \circle{4} }
\put(6.25, 2.5) { \makebox(0, 0) {$ x_{1} $} }
%
\put(12.5, 2.5) { \circle{4} }
\put(12.5, 2.5) { \makebox(0, 0) { $ x_{2} $ } }
%
\put(18.75, 2.5) { \circle{4} }
\put(18.75, 2.5) { \makebox(0, 0) { $ x_{3} $ } }
%
\put(6.25, 4.5) { \vector(3, 4){2.75} }
\put(12.5, 4.5) { \vector(-3, 4){2.75} }
\put(12.5, 4.5) { \vector(3, 4){2.75} }
\put(18.75, 4.5) { \vector(-3, 4){2.75} }
%
\put(10, 10) {\circle{4} } % Tweaked to the right
\put(9.375, 10) { \makebox(0, 0) { $f_{1}$ } }
%
\put(16.25, 10) {\circle{4} } % Tweaked to the right
\put(15.625, 10) { \makebox(0, 0) { $f_{2}$ } }
%
\put(9.375, 12) { \vector(3, 4){2.75} }
\put(15.625, 12) { \vector(-3, 4){2.75} }
%
\put(13, 17.5) {\circle{4} } % Tweaked to the right
\put(12.5, 17.5) { \makebox(0, 0) { $ g $ } }
%
% Middle Arrow
%
\put(21.875, 10) { \thicklines \vector(1, 0){6.25} }
%
% Stack
%
\put(33.5, 4) { \framebox(8, 2){ $x_{1}$} }
\put(33.5, 6) { \framebox(8, 2){ $x_{2}$ } }
\put(33.5, 8) { \framebox(8, 2){ $x_{3}$ } }
\put(33.5, 10) { \framebox(8, 2){ $f_{1}$ } }
\put(33.5, 12) { \framebox(8, 2){ $f_{2}$ } }
\put(33.5, 14) { \framebox(8, 2){ $g$ } }
%
\end{picture} 
\caption{
A topological sort of the expression graph yields a linear stack of nodes, 
sometimes known as a \textit{tape}, ordered such that a pass through the 
stack yields a valid forward or reverse sweep of the expression graph.
}
\label{fig:topologicalSort} 
\end{figure}

Nodes are implemented with the \verb|var_node| class which defines
default pushforward and pullback methods that can be specialized
for functions with structured Jacobians.  

Because the amount of storage for each node can vary widely depending 
on the corresponding function and the order of the desired linear differential 
operator, storage is decouples from each node.  Instead the necessary data 
is stored in three global stacks, the inputs stack, dual numbers stack, and 
partials stack, with \verb|var_node| containing only an address to the relevant 
data in each (Figure \ref{fig:architecture}), as well as accessor and mutator
methods that abstract the indirect storage.

\begin{figure}
\setlength{\unitlength}{0.1in} 
\centering
\begin{picture}(50, 30)
%
%\put(0, 0) { \framebox(50, 30){} }
%
%\put(0, 0) { \framebox(12.5, 30){} }
%\put(0, 0) { \framebox(25, 30){} }
%\put(0, 0) { \framebox(37.5, 30){} }
%
%\put(0, 0) { \framebox(50, 7.5){} }
%\put(0, 0) { \framebox(50, 15){} }
%\put(0, 0) { \framebox(50, 22.5){} }
%
% Var Body
%
\put(8.5, 2) { \makebox(8, 2){Var Node} }
\put(8.5, 6) { \framebox(8, 2){} }
\put(8.5, 8) { \framebox(8, 2){} }
\put(8.5, 10) { \framebox(8, 2){} }
\put(8.5, 12) { \framebox(8, 2){} }
\put(8.5, 14) { \framebox(8, 2){} }
\put(8.5, 16) { \framebox(8, 2){} }
\put(8.5, 18) { \framebox(8, 2){} }
\put(8.5, 20) { \framebox(8, 2){} }
\put(8.5, 22) { \framebox(8, 2){} }
\put(8.5, 24) { \framebox(8, 2){} }
%
% Inputs
%
\put(39, 24) { \makebox(8, 2){Inputs} }
\put(25, 22) { \framebox(2, 6){} }
\put(27, 22) { \framebox(2, 6){} }
\put(29, 22) { \framebox(2, 6){} }
\put(31, 22) { \framebox(2, 6){} }
\put(33, 22) { \framebox(2, 6){} }
\put(35, 22) { \framebox(2, 6){} }
\put(37, 22) { \framebox(2, 6){} }
%
% Dual Numbers
%
\put(39, 15) { \makebox(8, 2){Dual} }
\put(39, 13) { \makebox(8, 2){Numbers} }
\put(25, 12) { \framebox(2, 6){} }
\put(27, 12) { \framebox(2, 6){} }
\put(29, 12) { \framebox(2, 6){} }
\put(31, 12) { \framebox(2, 6){} }
\put(33, 12) { \framebox(2, 6){} }
\put(35, 12) { \framebox(2, 6){} }
\put(37, 12) { \framebox(2, 6){} }
%
% Partials
%
\put(39, 4) { \makebox(8, 2){Partials} }
\put(25, 2) { \framebox(2, 6){} }
\put(27, 2) { \framebox(2, 6){} }
\put(29, 2) { \framebox(2, 6){} }
\put(31, 2) { \framebox(2, 6){} }
\put(33, 2) { \framebox(2, 6){} }
\put(35, 2) { \framebox(2, 6){} }
\put(37, 2) { \framebox(2, 6){} }
%
% Arrows
%
\thicklines
\put(32, 22) { \vector(-1, -1){4} }
\put(34, 22) { \vector(0, -1){4} }
%
\put(16.5, 15) { \vector(4, 3){15.5} }
\put(16.5, 15) { \vector(1, 0){19.5} }
\put(16.5, 15) { \vector(2, -1){17.5} }
%
\end{picture} 
\caption{ 
Upon a topological sort (Figure \ref{fig:topologicalSort}), the expression graph 
is represented by a stack of \texttt{var\_node} objects.  The input nodes, 
dual numbers, and partial derivatives are stored in external stacks, with each 
\texttt{var\_node} storing only addresses to each.  Note that the input nodes 
address not the \texttt{var\_node} objects representing the input nodes, but rather
rather only the dual numbers of those nodes needed for implemented the
pushforward and pullback operators.
}
\label{fig:architecture} 
\end{figure}

\subsubsection{The Inputs Stack}

The inputs stack represented the edges in the expression graph
needed for directing the forward and reverse sweeps.  Because
the pushforward and pullback operators modify only the dual
numbers, edges index the dual numbers of any dependencies
directly (Figure \ref{fig:architecture}) and avoid the overhead
that would be acquired for indirect access through the \verb|var_node|
objects.

\subsubsection{Dual Number Stack}

The dual number stack stores the $2^{k}$ components of the $k$-order
dual numbers at each node.  For example, a first-order expression graph
will need only two elements for each node while a third-order expression 
graph will need eight (Figure \ref{fig:dualNumberStorage}).

\begin{figure}
\setlength{\unitlength}{0.1in} 
\centering
\begin{picture}(50, 20)
%
%\put(0, 0) { \framebox(50, 20){} }
%
% First-Order
%
\put(0, 15) { \makebox(8, 2){First-} }
\put(0, 13) { \makebox(8, 2){Order} }
\put(9, 17) { \makebox(2, 2){ $\ldots$ } }
\put(9, 11) { \makebox(2, 2){ $\ldots$ } }
\put(11, 12) { \framebox(4, 6){ $x $ } }
\put(15, 12) { \framebox(4, 6){ $ \delta x $ } }
\put(19, 17) { \makebox(2, 2){ $\ldots$ } }
\put(19, 11) { \makebox(2, 2){ $\ldots$ } }
%
% Second-Order
%
\put(0, 5) { \makebox(8, 2){Third-} }
\put(0, 3) { \makebox(8, 2){Order} }
\put(9, 7) { \makebox(2, 2){ $\ldots$ } }
\put(9, 1) { \makebox(2, 2){ $\ldots$ } }
\put(11, 2) { \framebox(4, 6){ $s$ } }
\put(15, 2) { \framebox(4, 6){ $\delta s$ } }
\put(19, 2) { \framebox(4, 6){ $\delta t$ } }
\put(23, 2) { \framebox(4, 6){ $\delta^{2} t$ } }
\put(27, 2) { \framebox(4, 6){ $\delta u$ } }
\put(31, 2) { \framebox(4, 6){ $\delta^{2} u$ } }
\put(35, 2) { \framebox(4, 6){ $\delta^{2} v$ } }
\put(39, 2) { \framebox(4, 6){ $\delta^{3} v$ } }
\put(43, 7) { \makebox(2, 2){ $\ldots$ } }
\put(43, 1) { \makebox(2, 2){ $\ldots$ } }
%
\end{picture} 
\caption{
The dual number stack is able to accommodate storage of dual numbers 
of any order without reallocating memory.  For example, first-order dual 
numbers require only two elements while third-order dual numbers require
eight elements.
}
\label{fig:dualNumberStorage} 
\end{figure}

\subsubsection{Partials Stack}

A common approach in many automatic differentiation implementations
is to compute partial derivatives as necessary and avoid storing them
in the expression graph.  This strategy is sound for first-order reverse
mode calculations where the partials are used only once, but higher-order
calculations require multiple sweeps that reuse the partials.  Recomputing
the partials for each sweep becomes a significant computational burden.

With a focus on implementing efficient higher-order methods, \nomad 
explicitly stores partial derivatives in a dedicated partials stack.  When 
constructing an $k$-order expression graph only the $k$-order partial 
derivatives and lower are stored, and only if the partial derivatives are 
non-zero.  For example, a second-order expression graph will calculate 
and store the first and second-order partial derivatives.

To avoid redundant calculations and storage, \nomad leverages the 
commutation of partial derivatives and stores only the unique higher-order 
values.  For a second-order calculation a node representing the component 
function $f: \mathbb{R}^{N} \rightarrow \mathbb{R}$ will store
%
\begin{equation*}
\frac{ \partial^{2} f }{ \partial x_{i} \partial x_{j} }, \, i \in 1, \ldots, N, j \in 1, \ldots i,
\end{equation*}
%
while a third-order calculation requires
%
\begin{equation*}
\frac{ \partial^{3} f }{ \partial x_{i} \partial x_{j} \partial x_{k} }, \, 
i \in 1, \ldots, N, j \in 1, \ldots i, k \in 1, \ldots, j.
\end{equation*}
%
For example, when executing a third-order calculation the node representing
a binary function, $f : \mathbb{R}^{2} \rightarrow \mathbb{R}$, requires
the storage demonstrated in Figure \ref{fig:partialsStorage}.

\begin{figure}
\setlength{\unitlength}{0.1in} 
\centering
\begin{picture}(50, 10)
%
%\put(0, 0) { \framebox(50, 10){} }
%
% Second-Order
%
\put(5, 7) { \makebox(2, 2){ $\ldots$ } }
\put(5, 1) { \makebox(2, 2){ $\ldots$ } }
\put(7, 2) { \framebox(4, 6){ $ \frac{ \partial f }{ \partial x} $ } }
\put(11, 2) { \framebox(4, 6){ $ \frac{ \partial f }{ \partial y} $ } }
\put(15, 2) { \framebox(4, 6){ $ \frac{ \partial^{2} f }{ \partial x^{2}} $ } }
\put(19, 2) { \framebox(4, 6){ $ \frac{ \partial^{2} f }{ \partial x \partial y} $ } }
\put(23, 2) { \framebox(4, 6){ $ \frac{ \partial^{2} f }{ \partial y^{2}} $ } }
\put(27, 2) { \framebox(4, 6){ $ \frac{ \partial^{3} f }{ \partial x^{3}} $ } }
\put(31, 2) { \framebox(4, 6){ $ \frac{ \partial^{3} f }{ \partial x^{2} \partial y} $ } }
\put(35, 2) { \framebox(4, 6){ $ \frac{ \partial^{3} f }{ \partial x \partial y^{3}} $ } }
\put(39, 2) { \framebox(4, 6){ $ \frac{ \partial^{3} f }{ \partial y^{3}} $ } }
\put(43, 7) { \makebox(2, 2){ $\ldots$ } }
\put(43, 1) { \makebox(2, 2){ $\ldots$ } }
%
\end{picture} 
\caption{
Only unique partial derivatives are stored in the partials stack,
as demonstrated here for node representing a binary function,
$f: \mathbb{R}^{2} \rightarrow \mathbb{R}$, in a third-order 
expression graph.
}
\label{fig:partialsStorage} 
\end{figure}

In general a function with $N$ inputs and non-vanishing derivatives at
all orders will require $\binom{N + M}{M}$ elements to store the unique
$M$th-order partial derivatives.

\section{Extending Functions to Accept Dual Numbers}

In order to implement reverse mode, a dual number-valued function needs to
create a node with the appropriate pushforward and pullback methods, store
the address of each input node, and then compute and store the value and 
necessary partial derivatives of the corresponding function.  Evaluating a 
composite dual number-valued function will then build an expression graph
initialized applying linear differential operators.

In \nomad dual numbers are exposed to the user via the \verb|var| class,
and \verb|var|-valued functions are responsible for the management of
the expression graph.

\subsection{The var Class}

\verb|var| is a lightweight class that abstracts the construction of the 
expression graph.  The class stores only an address to the \verb|var_node|
it creates, with a variety of helper functions for accessing data corresponding
to that node.

\verb|var| is templated to allow for compile-time configuration of the
expression graph.

\subsubsection{AutodiffOrder}

Maximum order operator the expression graph will admit.  Lower-order
graphs require less storage and compute fewer partials and end
significantly faster than their higher-order equivalents.  Takeaway --
use only the order you need, nothing more.

\subsubsection{StrictSmoothness}

Many algorithms using differential information require that the underlying
function be smooth in the sense that all of the necessary derivatives
exist \textit{everywhere}.  In particular, functions with even point
discontinuities in their derivatives are not applicable and will manifest
undesired pathologies.

With these algorithms in mind, \nomad takes a pedantic position and
disables functions and operators either with discontinuities anywhere 
in their derivatives or that may enable a discontinuous function, for
example conditional statements, unless the boolean template parameter
StrictSmoothness is set to true.

\subsubsection{ValidateIO}

Constructing large, composite functions that are robust to floating-point
pathologies like overflow and \verb|NaN| can be a significant challenge.
\nomad assists users by offering the ValidateIO template parameter.
When each function validates its inputs and outputs, throwing an
exception that identifies the source of the problem.  Because these
checks can be expensive they should be used for only debugging.

\subsection{var-valued Functions}

Validate inputs using validate methods.

Compute function value and push dual numbers onto stack
using push\_dual\_numbers method.

Push inputs onto stack using push\_input method

Compute partials onto stack using push\_partials method.

\subsubsection{Smooth Functions}

Example.

Note use of template parameters to avoid expensive computations
whenever possible.  Other relevant discussion.

Example of a \verb|var_node| specialization.

\subsubsection{Non-Smooth Functions}

Just show enable-if'd signature.

\section{The \nomad User Interface}

Functor-functional relationship.

Implement base functor with operator().  Example.

Compute linear differential operator by
passing instance of functor to function.  Functionals
evaluate functor to build expression graph, then
propagate execute forward and reverse sweeps
as necessary.  Gradient example.

\textbf{BEGIN OLD}

\subsection{Building the Expression Graph}

The \verb|var| class is responsible for building the internal representation
of the expression graph, either when constructed explicitly or implicitly
when a function is called.  Pushing a node onto the expression graph 
proceeds in three stages.

Firstly two global variables, \verb|next_inputs_delta| and 
\verb|next_partials_delta| have to be set, informing the stack of the memory
needed for the new node.  The \verb|var_body| class has a special
member dedicated to computing the number of partial derivatives needed
and is called as
%
\begin{verbatim}
next_inputs_delta = n_inputs;
next_partials_delta =
  var_body<autodiff_order, partials_order>::n_partials(n_inputs);
\end{verbatim}

Once these variables have been set the node can be pushed by constructing
a \verb|var_body| with an overloaded \verb|operator new|,
%
\begin{verbatim}
new var_body<autodiff_order, partials_order>(n_inputs);
\end{verbatim}
%
The overloaded \verb|operator new| checks if the current memory is large 
enough for the new node, allocating more if necessary, and then constructs 
the node at the top of the stack.  During construction addresses to the top of 
the dual numbers, inputs, and partial stack are set.

Once the node has been pushed, the state of the node can be pushed onto
the individual stacks.  Values are pushed onto the autodiff stack with the
command,
%
\begin{verbatim}
push_dual_numbers<autodiff_order>(value));
\end{verbatim},
%
which pushes $2^{\mathrm{autodiff\_order}}$ elements, the first being set to
value and the rest to zero.  Inputs are pushed with an address to the dual
number stack, for example,
%
\begin{verbatim}
push_inputs(input.dual_numbers());
\end{verbatim}
%
Finally partial derivatives are pushed one at a time using the sparse storage
pattern discussed above.  A binary function, for example, would require

%
\begin{verbatim}
    if (autodiff_order >= 1) {
      push_partials(df_dx);
      push_partials(df_dy);
    }
    if (autodiff_order >= 2) {
      push_partials(d2f_dx2);
      push_partials(d2f_dxdy);
      push_partials(d2f_dy2);
    }
    if (autodiff_order >= 3) {
      push_partials(df3_dx3);
      push_partials(df3_dx2dy);
      push_partials(df3_dxdy2);
      push_partials(df3_dy3);
    }
\end{verbatim}

Optimized derivations of \verb|var_body| may not use every stack and so may
not require each step.  Binary addition, for example, is able to efficiently 
compute partial derivatives on the fly and so does not need to worry about
storing any partials, let alone checking and expanding the partial derivative 
stack.

\section{User Interface} \label{sec:user_interface}

Linear differential operators are implemented in a functor-functional
pattern \textbf{reference}.

Functors are specified with any stateless class implementing
%
\begin{verbatim}
T operator()(const Eigen::VectorXd& x) const,
\end{verbatim}
%
where \verb|T| is any automatic differentiation variable and \verb|x|
contains the input values to the function.  Letting \verb|T| be
a template parameter is often more convenient than explicitly
defining the type.  For example, a functor implementing the function
%
\begin{equation*}
f \! \left( x, y, z \right) = \cos \! \left( e^{x} + e^{y} \right) / z
\end{equation*}
%
would be defined as
%
\begin{verbatim}
template <typename T>
class example_functor {
  T operator()(const Eigen::VectorXd& x) const {
    T v1 = x[0];
    T v2 = x[1];
    T v3 = x[2];
    return cos( exp(v1) + exp(v2) ) / v3;  
  }
};
\end{verbatim}

The linear differential operations themselves are implemented as
template functions taking functors as their first argument.  The 
gradient, for example, has the signature
%
\begin{verbatim}
  template <typename F>
  void gradient(const F& f,
                const Eigen::VectorXd& x,
                Eigen::VectorXd& g)
\end{verbatim}
%
and would be called as
%
\begin{verbatim}
Eigen::VectorXd& x = ...;
Eigen::VectorXd& g = Eigen::VectorXd::Ones(x.size());
gradient(example_functor<var<1U>>, x, g);
\end{verbatim}
%
Note the specialization of \verb|example_functor| to a first-order
automatic differentiation variable.  Any higher-order automatic
differentiation variable would also work.

Internally each functional calls \verb|F::operator()| to build up
the expression graph and then propagates perturbations and
sensitivities as necessary.
