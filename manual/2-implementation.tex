\chapter{Implementation}

The treatment of automatic differentiation as a consequence of
defining dual number-valued functions naturally motivates an
\textit{operator overloading} implementation \textbf{references},
where we introduce dual number types and overload common
operations and functions to accept these types.  \nomad is a C++
\textbf{reference} implementation of this strategy that heavily 
leverages template metaprogramming to optimize performance 
\textbf{reference}.

One complication to the implementation is that reverse mode
methods require the expression graph to be stored in memory.
\nomad builds the expression graph of the fly, storing nodes
in topological order via an arena-based memory allocation.

In this chapter we review the architecture and construction of
an expression graph in \nomad and investigate the resulting
user interface.

\section{Architecture} \label{sec:architecture}

\nomad defines a templated automatic differentiation type
%
\begin{verbatim}
<template short autodiff_order>
class var
\end{verbatim}
%
where \verb|autodiff_order| defines the order of the underlying
dual numbers.  If we needed to consider only methods that
could be implemented with forward mode automatic differentiation
then we could simply store the dual numbers as members of
\verb|var| and propagate them forward by overloading operators
and functions.

For example, a first-order automatic differentiation variable
might be implemented as
%
\begin{verbatim}
class var {
  var(double v, double g): first_val(v), first_grad(g) {}
  double first_val;
  double first_grad;
};
\end{verbatim}
%
with a function like the exponential overloaded as
%
\begin{verbatim}
var exp(const var& v) {
  return var( std::exp(v.first_val), std::exp(v.first_val) * v.first_grad);
}
\end{verbatim}

Although this approach works fine for first-order forward automatic
differentiation it does not scale well to higher-order methods that
require the backward propagation of sensitivities.  Instead of storing
the dual numbers directly, \verb|var| wraps a \verb|var_body| object
that represents and node of the expression graph and is stored
in global memory.

In the remainder of the section we will discuss how the expression
graph is represented in \nomad and how it is constructed by the
\verb|var| objects.

\subsection{Representing the Expression Graph With Stacks}

Each node of the expression graph, including edges to input nodes
and dual numbers, is represented by a \verb|var_body| object, and
the graph itself is represented by a topological sort of the \verb|var_body|
objects into a stack.  The topological sort insures that when traversing
the stack sequentially all of the input nodes will have been processed
before a dependent node is reached (Figure \ref{fig:topologicalSort}).

\begin{figure}
\setlength{\unitlength}{0.1in} 
\centering
\begin{picture}(50, 20)
%
%\put(0, 0) { \framebox(50, 20){} }
%\put(25, 0) { \framebox(25, 30){} }
%\put(25, 0) { \framebox(6.25, 30){} }
%\put(25, 0) { \framebox(12.5, 30){} }
%\put(25, 0) { \framebox(18.75, 30){} }
%
%\put(25, 0) { \framebox(3.125, 30){} }
%\put(25, 0) { \framebox(9.375, 30){} }
%\put(25, 0) { \framebox(15.625, 30){} }
%
% Expression Graph
%
\put(6.25, 2.5) { \circle{4} }
\put(6.25, 2.5) { \makebox(0, 0) {$ x_{1} $} }
%
\put(12.5, 2.5) { \circle{4} }
\put(12.5, 2.5) { \makebox(0, 0) { $ x_{2} $ } }
%
\put(18.75, 2.5) { \circle{4} }
\put(18.75, 2.5) { \makebox(0, 0) { $ x_{3} $ } }
%
\put(6.25, 4.5) { \vector(3, 4){2.75} }
\put(12.5, 4.5) { \vector(-3, 4){2.75} }
\put(12.5, 4.5) { \vector(3, 4){2.75} }
\put(18.75, 4.5) { \vector(-3, 4){2.75} }
%
\put(10, 10) {\circle{4} } % Tweaked to the right
\put(9.375, 10) { \makebox(0, 0) { $y_{1}$ } }
%
\put(16.25, 10) {\circle{4} } % Tweaked to the right
\put(15.625, 10) { \makebox(0, 0) { $y_{2}$ } }
%
\put(9.375, 12) { \vector(3, 4){2.75} }
\put(15.625, 12) { \vector(-3, 4){2.75} }
%
\put(13, 17.5) {\circle{4} } % Tweaked to the right
\put(12.5, 17.5) { \makebox(0, 0) { $ z $ } }
%
% Middle Arrow
%
\put(21.875, 10) { \thicklines \vector(1, 0){6.25} }
%
% Stack
%
\put(33.5, 4) { \framebox(8, 2){ $x_{1}$} }
\put(33.5, 6) { \framebox(8, 2){ $x_{2}$ } }
\put(33.5, 8) { \framebox(8, 2){ $x_{3}$ } }
\put(33.5, 10) { \framebox(8, 2){ $y_{1}$ } }
\put(33.5, 12) { \framebox(8, 2){ $y_{2}$ } }
\put(33.5, 14) { \framebox(8, 2){ $z$ } }
%
\end{picture} 
\caption{
Topological sort ensures that when sweeping across the stack a node will not
be processed until all dependent nodes have been processed.  From a message
passing perspective this ensures that once a node is reached it will have
received all messages from its inputs.  Note that this is only one possible
topological sort -- it's not unique.
}
\label{fig:topologicalSort} 
\end{figure}

\textbf{Okay, need a reasonable argument here for why we use separate
stacks for the storage.  Dynamic sizing is bad -- do the stacks just make
an arena-based allocation easier?}

\subsubsection{Var Body Stack} \label{subsubsec:var_body}

Nodes in the expression graph are represented by \texttt{var\_body}
objects, which address the necessary storage and implement
methods for propagating perturbations and sensitivities.

Dual numbers, inputs, and partials are stored in separate stacks,
allowing dynamic storage with the same \texttt{var\_body} class.
\texttt{var\_body} itself simply stores the addresses of the relevant
data within those stacks (Figure \ref{fig:architecture}).

In the case of heavily-used functions, especially those with sparse 
partial derivatives, significant computations gains can be found in
optimizing the propagation routines and partial storage.  For these
heavily-used functions we implement \texttt{var\_body} derivations.

\begin{figure}
\setlength{\unitlength}{0.1in} 
\centering
\begin{picture}(50, 30)
%
%\put(0, 0) { \framebox(50, 30){} }
%
%\put(0, 0) { \framebox(12.5, 30){} }
%\put(0, 0) { \framebox(25, 30){} }
%\put(0, 0) { \framebox(37.5, 30){} }
%
%\put(0, 0) { \framebox(50, 7.5){} }
%\put(0, 0) { \framebox(50, 15){} }
%\put(0, 0) { \framebox(50, 22.5){} }
%
% Var Body
%
\put(8.5, 2) { \makebox(8, 2){Var Body} }
\put(8.5, 6) { \framebox(8, 2){} }
\put(8.5, 8) { \framebox(8, 2){} }
\put(8.5, 10) { \framebox(8, 2){} }
\put(8.5, 12) { \framebox(8, 2){} }
\put(8.5, 14) { \framebox(8, 2){} }
\put(8.5, 16) { \framebox(8, 2){} }
\put(8.5, 18) { \framebox(8, 2){} }
\put(8.5, 20) { \framebox(8, 2){} }
\put(8.5, 22) { \framebox(8, 2){} }
\put(8.5, 24) { \framebox(8, 2){} }
%
% Inputs
%
\put(39, 24) { \makebox(8, 2){Inputs} }
\put(25, 22) { \framebox(2, 6){} }
\put(27, 22) { \framebox(2, 6){} }
\put(29, 22) { \framebox(2, 6){} }
\put(31, 22) { \framebox(2, 6){} }
\put(33, 22) { \framebox(2, 6){} }
\put(35, 22) { \framebox(2, 6){} }
\put(37, 22) { \framebox(2, 6){} }
%
% Dual Numbers
%
\put(39, 15) { \makebox(8, 2){Dual} }
\put(39, 13) { \makebox(8, 2){Numbers} }
\put(25, 12) { \framebox(2, 6){} }
\put(27, 12) { \framebox(2, 6){} }
\put(29, 12) { \framebox(2, 6){} }
\put(31, 12) { \framebox(2, 6){} }
\put(33, 12) { \framebox(2, 6){} }
\put(35, 12) { \framebox(2, 6){} }
\put(37, 12) { \framebox(2, 6){} }
%
% Partials
%
\put(39, 4) { \makebox(8, 2){Partials} }
\put(25, 2) { \framebox(2, 6){} }
\put(27, 2) { \framebox(2, 6){} }
\put(29, 2) { \framebox(2, 6){} }
\put(31, 2) { \framebox(2, 6){} }
\put(33, 2) { \framebox(2, 6){} }
\put(35, 2) { \framebox(2, 6){} }
\put(37, 2) { \framebox(2, 6){} }
%
% Arrows
%
\thicklines
\put(32, 22) { \vector(-1, -1){4} }
\put(34, 22) { \vector(0, -1){4} }
%
\put(16.5, 15) { \vector(4, 3){15.5} }
\put(16.5, 15) { \vector(1, 0){19.5} }
\put(16.5, 15) { \vector(2, -1){17.5} }
%
\end{picture} 
\caption{ 
Each node in the expression graph is represented by a 
\texttt{var\_body} object stored in the \texttt{var\_body} stack.  
Storage of the inputs, dual numbers, and
partial derivatives is split out from this representation, with each \texttt{var\_body}
storing only addresses to the relevant stacks.  Note that the inputs address not
the input \texttt{var\_body} objects themselves but rather their dual numbers, 
allowing the direct access needed for computations and avoiding any overhead
from indirection. 
}
\label{fig:architecture} 
\end{figure}

\subsubsection{Dual Number Stack}

The dual number stack stores the values and gradients of the dual
numbers at each node.  For example, a first-order expression graph
will need only two elements for each node while a third-order expression 
graph will need eight (Figure \ref{fig:dualNumberStorage}).  In general
$2^{n}$ addresses must be reserved for each node of an $n$-th
order expression graph.

\begin{figure}
\setlength{\unitlength}{0.1in} 
\centering
\begin{picture}(50, 20)
%
%\put(0, 0) { \framebox(50, 20){} }
%
% First-Order
%
\put(0, 15) { \makebox(8, 2){First-} }
\put(0, 13) { \makebox(8, 2){Order} }
\put(9, 12) { \framebox(4, 6){ $x $ } }
\put(13, 12) { \framebox(4, 6){ $ \delta x $ } }
\put(17, 17) { \makebox(2, 2){ $\ldots$ } }
\put(17, 11) { \makebox(2, 2){ $\ldots$ } }
%
% Second-Order
%
\put(0, 5) { \makebox(8, 2){Third-} }
\put(0, 3) { \makebox(8, 2){Order} }
\put(9, 2) { \framebox(4, 6){ $s$ } }
\put(13, 2) { \framebox(4, 6){ $\delta s$ } }
\put(17, 2) { \framebox(4, 6){ $\delta t$ } }
\put(21, 2) { \framebox(4, 6){ $\delta^{2} t$ } }
\put(25, 2) { \framebox(4, 6){ $\delta u$ } }
\put(29, 2) { \framebox(4, 6){ $\delta^{2} u$ } }
\put(33, 2) { \framebox(4, 6){ $\delta^{2} v$ } }
\put(37, 2) { \framebox(4, 6){ $\delta^{3} v$ } }
\put(41, 7) { \makebox(2, 2){ $\ldots$ } }
\put(41, 1) { \makebox(2, 2){ $\ldots$ } }
%
\end{picture} 
\caption{
A separate dual number stack is able to accommodate storage
of dual numbers of any order.  For example, first-order dual numbers
require only two elements while third-order dual numbers require
eight elements.
}
\label{fig:dualNumberStorage} 
\end{figure}

\subsubsection{Input Stack}

The input stack stores the edges to any dependent nodes.  For
optimal performance the edges index the dual numbers of those
nodes directly and avoid indirect access through the nodes
themselves (Figure \ref{fig:architecture}).

\subsubsection{Partials Stack}

A common approach in many automatic differentiation implementations
is to compute partial derivatives on the fly and avoid storing them in
the expression graph.  In order to compute higher-order differential operations,
however, the partials are reused in every sweep and their repeated computation
can be a significant computational burden.

Given its focus on higher-order methods, \nomad explicitly stores partial 
derivatives in a dedicated partials stack.  When constructing an $n$th-order
expression graph only the $n$th-order partial derivatives and lower are
stored, and only if the partial derivatives are non-zero.  For example, 
a second-order expression graph will calculate and store the first and
second-order partial derivatives.

To avoid redundant calculations and storage, \nomad leverages the commutation
of partial derivatives and considers only the unique higher-order values.  
For a node representing a function $f \! \left( x_{1}, \ldots, x_{N} \right)$, 
at second-order the stack will store
%
\begin{equation*}
\frac{ \partial^{2} f }{ \partial x_{i} \partial x_{j} }, \, i \in 1, \ldots, N, j \in 1, \ldots i.
\end{equation*}
%
and at third-order
%
\begin{equation*}
\frac{ \partial^{3} f }{ \partial x_{i} \partial x_{j} \partial x_{k} }, \, 
i \in 1, \ldots, N, j \in 1, \ldots i, k \in 1, \ldots, j.
\end{equation*}
%
For example, the storage for a binary function $f \! \left(x, y \right)$
is given in Figure \ref{fig:partialsStorage}.

\begin{figure}
\setlength{\unitlength}{0.1in} 
\centering
\begin{picture}(50, 10)
%
%\put(0, 0) { \framebox(50, 10){} }
%
% Second-Order
%
\put(7, 2) { \framebox(4, 6){ $ \frac{ \partial f }{ \partial x} $ } }
\put(11, 2) { \framebox(4, 6){ $ \frac{ \partial f }{ \partial y} $ } }
\put(15, 2) { \framebox(4, 6){ $ \frac{ \partial^{2} f }{ \partial x^{2}} $ } }
\put(19, 2) { \framebox(4, 6){ $ \frac{ \partial^{2} f }{ \partial x \partial y} $ } }
\put(23, 2) { \framebox(4, 6){ $ \frac{ \partial^{2} f }{ \partial y^{2}} $ } }
\put(27, 2) { \framebox(4, 6){ $ \frac{ \partial^{3} f }{ \partial x^{3}} $ } }
\put(31, 2) { \framebox(4, 6){ $ \frac{ \partial^{3} f }{ \partial x^{2} \partial y} $ } }
\put(35, 2) { \framebox(4, 6){ $ \frac{ \partial^{3} f }{ \partial x \partial y^{3}} $ } }
\put(39, 2) { \framebox(4, 6){ $ \frac{ \partial^{3} f }{ \partial y^{3}} $ } }
\put(43, 7) { \makebox(2, 2){ $\ldots$ } }
\put(43, 1) { \makebox(2, 2){ $\ldots$ } }
%
\end{picture} 
\caption{
Only unique partial derivatives are stored in the partials stack,
as demonstrated here for node representing a binary function 
$f \! \left( x, y \right)$ in a third-order expression graph.
}
\label{fig:partialsStorage} 
\end{figure}

In general a function with $N$ inputs and non-vanishing derivatives at
all orders will require $\binom{N + M}{M}$ elements to store the unique
$M$th-order partial derivatives.

\subsection{Building the Expression Graph}

The \verb|var| class is responsible for building the internal representation
of the expression graph, either when constructed explicitly or implicitly
when a function is called.  Pushing a node onto the expression graph 
proceeds in three stages.

Firstly two global variables, \verb|next_inputs_delta| and 
\verb|next_partials_delta| have to be set, informing the stack of the memory
needed for the new node.  The \verb|var_body| class has a special
member dedicated to computing the number of partial derivatives needed
and is called as
%
\begin{verbatim}
next_inputs_delta = n_inputs;
next_partials_delta =
  var_body<autodiff_order, partials_order>::n_partials(n_inputs);
\end{verbatim}

Once these variables have been set the node can be pushed by constructing
a \verb|var_body| with an overloaded \verb|operator new|,
%
\begin{verbatim}
new var_body<autodiff_order, partials_order>(n_inputs);
\end{verbatim}
%
The overloaded \verb|operator new| checks if the current memory is large 
enough for the new node, allocating more if necessary, and then constructs 
the node at the top of the stack.  During construction addresses to the top of 
the dual numbers, inputs, and partial stack are set.

Once the node has been pushed, the state of the node can be pushed onto
the individual stacks.  Values are pushed onto the autodiff stack with the
command,
%
\begin{verbatim}
push_dual_numbers<autodiff_order>(value));
\end{verbatim},
%
which pushes $2^{\mathrm{autodiff\_order}}$ elements, the first being set to
value and the rest to zero.  Inputs are pushed with an address to the dual
number stack, for example,
%
\begin{verbatim}
push_inputs(input.dual_numbers());
\end{verbatim}
%
Finally partial derivatives are pushed one at a time using the sparse storage
pattern discussed above.  A binary function, for example, would require

%
\begin{verbatim}
    if (autodiff_order >= 1) {
      push_partials(df_dx);
      push_partials(df_dy);
    }
    if (autodiff_order >= 2) {
      push_partials(d2f_dx2);
      push_partials(d2f_dxdy);
      push_partials(d2f_dy2);
    }
    if (autodiff_order >= 3) {
      push_partials(df3_dx3);
      push_partials(df3_dx2dy);
      push_partials(df3_dxdy2);
      push_partials(df3_dy3);
    }
\end{verbatim}

Optimized derivations of \verb|var_body| may not use every stack and so may
not require each step.  Binary addition, for example, is able to efficiently 
compute partial derivatives on the fly and so does not need to worry about
storing any partials, let alone checking and expanding the partial derivative 
stack.

\section{User Interface} \label{sec:user_interface}

Linear differential operators are implemented in a functor-functional
pattern \textbf{reference}.

Functors are specified with any stateless class implementing
%
\begin{verbatim}
T operator()(const Eigen::VectorXd& x) const,
\end{verbatim}
%
where \verb|T| is any automatic differentiation variable and \verb|x|
contains the input values to the function.  Letting \verb|T| be
a template parameter is often more convenient than explicitly
defining the type.  For example, a functor implementing the function
%
\begin{equation*}
f \! \left( x, y, z \right) = \cos \! \left( e^{x} + e^{y} \right) / z
\end{equation*}
%
would be defined as
%
\begin{verbatim}
template <typename T>
class example_functor {
  T operator()(const Eigen::VectorXd& x) const {
    T v1 = x[0];
    T v2 = x[1];
    T v3 = x[2];
    return cos( exp(v1) + exp(v2) ) / v3;  
  }
};
\end{verbatim}

The linear differential operations themselves are implemented as
template functions taking functors as their first argument.  The 
gradient, for example, has the signature
%
\begin{verbatim}
  template <typename F>
  void gradient(const F& f,
                const Eigen::VectorXd& x,
                Eigen::VectorXd& g)
\end{verbatim}
%
and would be called as
%
\begin{verbatim}
Eigen::VectorXd& x = ...;
Eigen::VectorXd& g = Eigen::VectorXd::Ones(x.size());
gradient(example_functor<var<1U>>, x, g);
\end{verbatim}
%
Note the specialization of \verb|example_functor| to a first-order
automatic differentiation variable.  Any higher-order automatic
differentiation variable would also work.

Internally each functional calls \verb|F::operator()| to build up
the expression graph and then propagates perturbations and
sensitivities as necessary.
